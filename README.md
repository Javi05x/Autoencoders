# ğŸ§  PrÃ¡ctica 2: Autoencoders - Denoising y Super-ResoluciÃ³n

ImplementaciÃ³n de autoencoders convolucionales para dos tareas principales: eliminaciÃ³n de ruido gaussiano y super-resoluciÃ³n de imÃ¡genes usando el dataset MNIST.

---

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa y compara diferentes arquitecturas de autoencoders para:

1. **Denoising (EliminaciÃ³n de ruido)**: ReconstrucciÃ³n de imÃ¡genes corruptas con ruido gaussiano
2. **Super-ResoluciÃ³n**: Aumento de resoluciÃ³n desde imÃ¡genes de baja calidad (7Ã—7 y 14Ã—14) a 28Ã—28 pÃ­xeles

### ğŸ¯ Objetivos

- Implementar autoencoders convolucionales efectivos
- Comparar el rendimiento en diferentes niveles de degradaciÃ³n
- Analizar los lÃ­mites de reconstrucciÃ³n desde informaciÃ³n extremadamente limitada
- Demostrar la capacidad de los modelos para tareas mÃºltiples (SR + denoising simultÃ¡neo)

---

## ğŸ—ï¸ Arquitectura

### Modelo de Denoising

```
Encoder: 28Ã—28 â†’ 14Ã—14 â†’ 7Ã—7 â†’ 1Ã—1 (64 canales)
Decoder: 1Ã—1 â†’ 7Ã—7 â†’ 14Ã—14 â†’ 28Ã—28
```

### Modelo de Super-ResoluciÃ³n

#### SR 7Ã—7 â†’ 28Ã—28
```
Encoder: 7Ã—7 (1â†’64â†’128â†’256 canales)
Decoder: 7Ã—7 â†’ 14Ã—14 â†’ 28Ã—28 (ConvTranspose2d + Conv2d)
```

#### SR 14Ã—14 â†’ 28Ã—28
```
Encoder: 14Ã—14 (1â†’32â†’64 canales)
Decoder: 14Ã—14 â†’ 28Ã—28 (ConvTranspose2d + Conv2d)
```

---

## ğŸ“Š Modelos Entrenados

| Modelo | Entrada | DegradaciÃ³n | Loss Inicial | Loss Final | Mejora | Epochs |
|--------|---------|-------------|--------------|------------|--------|--------|
| **Denoising** | 28Ã—28 | Ruido Ïƒ=0.4 | 0.0426 | 0.0106 | 75.14% | 10 |
| **SR 7Ã—7** | 7Ã—7 (49 px) | Solo resoluciÃ³n | 0.1125 | 0.0190 | 83.10% | 15 |
| **SR 14Ã—14 limpio** | 14Ã—14 (196 px) | Solo resoluciÃ³n | 0.0077 | 0.0014 | 81.72% | 10 |
| **SR 14Ã—14 ruidoso** | 14Ã—14 (196 px) | ResoluciÃ³n + ruido Ïƒ=0.15 | 0.1130 | 0.0080 | 92.93% | 10 |

---

## ğŸš€ InstalaciÃ³n

### Requisitos

```bash
Python 3.8+
PyTorch 2.0+
torchvision
numpy
matplotlib
```

### Instalar dependencias

```bash
pip install torch torchvision numpy matplotlib
```

---

## ğŸ’» Uso

### Entrenamiento completo

```python
# Ejecutar el notebook completo
jupyter notebook Practica2.ipynb
```

### Entrenar modelos individuales

```python
# Denoising
model_denoise = ModelFactory.create_denoising_autoencoder(device)
denoising_task = DenoisingTask(device, noise_std=0.4)
trainer_denoise.train(train_loader, num_epochs=10, ...)

# Super-resoluciÃ³n 7x7
model_sr7 = ModelFactory.create_super_resolution_autoencoder(device, input_size=7)
sr7_task = SuperResolutionTask(device, low_res_size=7)
trainer_sr7.train(train_loader, num_epochs=15, ...)

# Super-resoluciÃ³n 14x14 con ruido
model_sr14 = ModelFactory.create_super_resolution_autoencoder(device, input_size=14)
sr14_task = SuperResolutionTask(device, low_res_size=14, add_noise=True, noise_std=0.15)
trainer_sr14.train(train_loader, num_epochs=10, ...)
```

---

## ğŸ“ˆ Resultados

### Convergencia de PÃ©rdidas

Los modelos muestran patrones de convergencia distintos segÃºn la dificultad de la tarea:

- **SR 14Ã—14 sin ruido**: Convergencia casi instantÃ¡nea (epoch 1-2) â†’ Tarea trivial
- **Denoising**: Convergencia rÃ¡pida (epoch 3-4)
- **SR 7Ã—7**: CaÃ­da dramÃ¡tica en epoch 4-5, luego estabilizaciÃ³n
- **SR 14Ã—14 con ruido**: Convergencia gradual mÃ¡s lenta (epoch 6-7)

### Observaciones Clave

1. **SR 7Ã—7 representa el lÃ­mite prÃ¡ctico**: Loss final de 0.019 (el mÃ¡s alto), indicando que reconstruir desde 49 pÃ­xeles es extremadamente desafiante pero viable.

2. **AÃ±adir ruido transforma tareas triviales**: El SR 14Ã—14 pasa de trivial (loss inicial 0.008) a desafiante (0.113) con ruido gaussiano.

3. **Mejor mejora porcentual**: SR 14Ã—14 con ruido (92.93%), demostrando capacidad de multi-tarea (super-resoluciÃ³n + denoising).

---

## ğŸ¨ Visualizaciones

Cada modelo genera visualizaciones con 3 filas:

```
Fila 1: ImÃ¡genes originales (28Ã—28, nÃ­tidas)
Fila 2: ImÃ¡genes degradadas (ruido/baja resoluciÃ³n)
Fila 3: ImÃ¡genes reconstruidas por el autoencoder
```

**Nota tÃ©cnica**: Se utiliza `interpolation='nearest'` en matplotlib para evitar artefactos visuales en imÃ¡genes de baja resoluciÃ³n.

---

## ğŸ”¬ AnÃ¡lisis TÃ©cnico

### Por quÃ© NO se aÃ±adiÃ³ ruido al SR 7Ã—7

La decisiÃ³n de no aÃ±adir ruido gaussiano a las imÃ¡genes de 7Ã—7 se fundamenta en:

1. **InformaciÃ³n limitada**: 49 pÃ­xeles vs 784 objetivo (ratio 1:16)
2. **DegradaciÃ³n suficiente**: El modelo ya alcanza el loss final mÃ¡s alto (0.019)
3. **LÃ­mite de viabilidad**: AÃ±adir ruido comprometerÃ­a la convergencia sin aportar valor analÃ­tico

En contraste, el SR 14Ã—14 (196 pÃ­xeles, ratio 1:4) tiene margen para degradaciÃ³n adicional, resultando en la comparaciÃ³n mÃ¡s interesante del experimento.

### Mejoras ArquitectÃ³nicas

El modelo SR 7Ã—7 utiliza una arquitectura mÃ¡s profunda (64â†’128â†’256 canales) comparada con el SR 14Ã—14 (32â†’64 canales) para compensar la extrema reducciÃ³n de informaciÃ³n de entrada.

---

## ğŸ§ª Experimentos Adicionales

### HiperparÃ¡metros Probados

- **Ruido gaussiano**: Ïƒ âˆˆ {0.3, 0.4, 0.5} para denoising
- **Ruido en SR**: Ïƒ=0.15 para 14Ã—14 (Ã³ptimo para dificultad media-alta)
- **Epochs**: 10 (estÃ¡ndar), 15 (SR 7Ã—7 para mejor convergencia)
- **Learning rate**: 1e-3 con weight decay 1e-5

---

## ğŸ“‚ Estructura del Proyecto

```
.
â”œâ”€â”€ Practica2.ipynb          # Notebook principal con todo el cÃ³digo
â”œâ”€â”€ README.md                # Este archivo
â”œâ”€â”€ data/                    # Dataset MNIST (descarga automÃ¡tica)
â””â”€â”€ results/                 # Visualizaciones y grÃ¡ficas generadas
    â”œâ”€â”€ denoising_results.png
    â”œâ”€â”€ sr7_results.png
    â”œâ”€â”€ sr14_clean_results.png
    â”œâ”€â”€ sr14_noisy_results.png
    â””â”€â”€ loss_comparison.png
```

---

## ğŸ“ Conceptos Implementados

- **Autoencoders convolucionales**: ReducciÃ³n y reconstrucciÃ³n de dimensionalidad
- **Skip connections implÃ­citas**: A travÃ©s de la arquitectura simÃ©trica
- **Multi-task learning**: Super-resoluciÃ³n + denoising simultÃ¡neo
- **Transfer learning concepts**: Misma arquitectura, diferentes tareas
- **Patrones de diseÃ±o**: Factory, Strategy, Service Layer

---

## ğŸ“š Referencias

- Dataset: [MNIST - Yann LeCun](http://yann.lecun.com/exdb/mnist/)
- Framework: [PyTorch](https://pytorch.org/)
- Autoencoders: [Deep Learning Book - Ian Goodfellow](https://www.deeplearningbook.org/)

---

## ğŸ‘¤ Autor

**Tu Nombre**  
Universidad / Curso  
PrÃ¡ctica 2 - Redes Neuronales y Deep Learning

---

## ğŸ“„ Licencia

Este proyecto es material educativo para la asignatura de Deep Learning.

---

## ğŸ™ Agradecimientos

- Profesores y equipo docente del curso
- Comunidad de PyTorch por la documentaciÃ³n
- Dataset MNIST por ser el benchmark estÃ¡ndar

---

## ğŸ“ Contacto

Para dudas o sugerencias:
- Email: tu.email@universidad.edu
- GitHub: [@tu-usuario](https://github.com/tu-usuario)

---

**â­ Si este proyecto te fue Ãºtil, no olvides darle una estrella!**
